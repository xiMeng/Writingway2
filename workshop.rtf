{\rtf1\ansi\deff3\adeflang1025
{\fonttbl{\f0\froman\fprq2\fcharset0 Times New Roman;}{\f1\froman\fprq2\fcharset2 Symbol;}{\f2\fswiss\fprq2\fcharset0 Arial;}{\f3\froman\fprq2\fcharset0 Liberation Serif{\*\falt Times New Roman};}{\f4\fswiss\fprq2\fcharset0 Liberation Sans{\*\falt Arial};}{\f5\fmodern\fprq1\fcharset0 Liberation Mono{\*\falt Courier New};}{\f6\fnil\fprq0\fcharset2 OpenSymbol{\*\falt Arial Unicode MS};}{\f7\fnil\fprq2\fcharset0 Microsoft YaHei;}{\f8\fnil\fprq2\fcharset0 NSimSun;}{\f9\fmodern\fprq1\fcharset0 NSimSun;}{\f10\fnil\fprq2\fcharset0 Arial;}{\f11\fswiss\fprq0\fcharset128 Arial;}}
{\colortbl;\red0\green0\blue0;\red0\green0\blue255;\red0\green255\blue255;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red255\green255\blue0;\red255\green255\blue255;\red0\green0\blue128;\red0\green128\blue128;\red0\green128\blue0;\red128\green0\blue128;\red128\green0\blue0;\red128\green128\blue0;\red128\green128\blue128;\red192\green192\blue192;}
{\stylesheet{\s0\snext0\rtlch\af10\afs24\alang1081 \ltrch\lang1031\langfe2052\hich\af3\loch\widctlpar\hyphpar0\ltrpar\cf0\f3\fs24\lang1031\kerning1\dbch\af8\langfe2052 Normal;}
{\s1\sbasedon20\snext21\rtlch\af10\afs48\ab \ltrch\hich\af3\loch\ilvl0\outlinelevel0\sb240\sa120\keepn\f3\fs48\b\dbch\af8 Heading 1;}
{\s2\sbasedon20\snext21\rtlch\af10\afs36\ab \ltrch\hich\af3\loch\ilvl1\outlinelevel1\sb200\sa120\keepn\f3\fs36\b\dbch\af8 Heading 2;}
{\*\cs15\snext15\rtlch\ab \ltrch\loch\b Strong;}
{\*\cs16\snext16\loch\cf9\ul\ulc0 Hyperlink;}
{\*\cs17\snext17\rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 Bullets;}
{\*\cs18\snext18\rtlch\ai \ltrch\loch\i Emphasis;}
{\*\cs19\snext19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9 Source Text;}
{\s20\sbasedon0\snext21\rtlch\af10\afs28 \ltrch\hich\af4\loch\sb240\sa120\keepn\f4\fs28\dbch\af7 Heading;}
{\s21\sbasedon0\snext21\loch\sl276\slmult1\sb0\sa140 Body Text;}
{\s22\sbasedon21\snext22\rtlch\af11 \ltrch\loch\sl276\slmult1\sb0\sa140 List;}
{\s23\sbasedon0\snext23\rtlch\af11\afs24\ai \ltrch\loch\sb120\sa120\noline\fs24\i Caption;}
{\s24\sbasedon0\snext24\rtlch\af11 \ltrch\loch\noline Index;}
}{\*\listtable{\list\listtemplateid1
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li709}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li1418}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2127}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2836}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li3545}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4254}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4963}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li5672}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li6381}\listid1}
{\list\listtemplateid2
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li709}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li1418}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2127}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2836}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li3545}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4254}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4963}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li5672}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li6381}\listid2}
{\list\listtemplateid3
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li709}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li1418}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2127}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2836}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li3545}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4254}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4963}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li5672}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li6381}\listid3}
{\list\listtemplateid4
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li709}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li1418}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2127}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2836}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li3545}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4254}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4963}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li5672}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li6381}\listid4}
{\list\listtemplateid5
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li709}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li1418}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2127}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2836}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li3545}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4254}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4963}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li5672}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li6381}\listid5}
{\list\listtemplateid6
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li709}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li1418}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2127}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2836}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li3545}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4254}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4963}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li5672}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li6381}\listid6}
{\list\listtemplateid7
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li709}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li1418}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2127}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2836}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li3545}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4254}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4963}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li5672}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li6381}\listid7}
{\list\listtemplateid8
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li709}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li1418}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2127}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li2836}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li3545}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4254}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li4963}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li5672}
{\listlevel\levelnfc23\leveljc0\levelstartat1\levelfollow0{\leveltext \'01\u8226 ?;}{\levelnumbers;}\f6\rtlch\af6 \ltrch\loch\fi-283\li6381}\listid8}
{\list\listtemplateid9
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}
{\listlevel\levelnfc255\leveljc0\levelstartat1\levelfollow2{\leveltext \'00;}{\levelnumbers;}\fi0\li0}\listid9}
}{\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}}{\*\generator LibreOffice/7.6.7.2$Windows_X86_64 LibreOffice_project/dd47e4b30cb7dab30588d6c79c651f218165e3c5}{\info{\creatim\yr2025\mo11\dy15\hr23\min0}{\revtim\yr2025\mo11\dy15\hr23\min1}{\printim\yr0\mo0\dy0\hr0\min0}}{\*\userprops}\deftab709
\hyphauto1\viewscale100\formshade\nobrkwrptbl\paperh16838\paperw11906\margl1134\margr1134\margt1134\margb1134\sectd\sbknone\sftnnar\saftnnrlc\sectunlocked1\pgwsxn11906\pghsxn16838\marglsxn1134\margrsxn1134\margtsxn1134\margbsxn1134\ftnbj\ftnstart1\ftnrstcont\ftnnar\aenddoc\aftnrstcont\aftnstart1\aftnnrlc
{\*\ftnsep\chftnsep}\pgndec\pard\plain \s1\rtlch\af10\afs48\ab \ltrch\hich\af3\loch\ilvl0\outlinelevel0\sb240\sa120\keepn\f3\fs48\b\dbch\af8\ql\sb240\sa120\ltrpar{\loch
Workshop Chat in Writingway: Architecture and Functionality}
\par \pard\plain \s2\rtlch\af10\afs36\ab \ltrch\hich\af3\loch\ilvl1\outlinelevel1\sb200\sa120\keepn\f3\fs36\b\dbch\af8\ql\ltrpar{\loch
Overview of the Workshop Chat Feature}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
Writingway\u8217\'92s }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Workshop Chat}{\loch
 is a dedicated, chat-based interface for interactive brainstorming with an AI assistant. It allows the writer to converse with an LLM (Large Language Model) much like using ChatGPT, but within the context of their writing project. The Workshop Chat is used for tasks such as idea generation, plot brainstorming, or even role-playing conversations with characters}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=Workshop%20Chat%20,a%20separate%20window%20or%20pane" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=Prompt%20Selector%20dropdown%20containing%20different,use%20shorter%20replies%20to%20save" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. Unlike one-off AI prompts, this feature maintains a running dialogue (with memory of previous messages) and can pull in story context to keep the AI\u8217\'92s responses relevant to the writer\u8217\'92s work.}
\par \pard\plain \s2\rtlch\af10\afs36\ab \ltrch\hich\af3\loch\ilvl1\outlinelevel1\sb200\sa120\keepn\f3\fs36\b\dbch\af8\ql\ltrpar{\loch
User Interface Structure}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
The Workshop Chat opens as a separate window or pane (accessible via a chat bubble icon in the toolbar)}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=Workshop%20Chat%20,a%20separate%20window%20or%20pane" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. The UI is split into multiple sections:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls1 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Conversation List (Left Panel):}{\loch
 On the left side, there is a list of conversation threads, each representing a separate chat session}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,without%20context%20from%20previous%20chats" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. By default, you might see }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Chat 1}{\loch
 (the first session). Users can have multiple chats in parallel \u8211\'96 for example, one chat could be brainstorming a subplot while another is discussing a character. A }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
\u8220\'93New Chat\u8221\'94}{\loch
 button allows starting a fresh conversation thread; clicking it creates a new entry (e.g. \u8220\'93Chat 2\u8221\'94) in this list}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=chat%20session%2C%20so%20you%20can,without%20context%20from%20previous%20chats" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. Users can switch between sessions by selecting them from the list, which loads that chat\u8217\'92s history on the right. This setup lets writers manage different topics or lines of inquiry separately without mixing up contexts.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls1 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Chat Log (Right Panel, top):}{\loch
 The main area on the right displays the conversation between the user and the AI, similar to a messaging app}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,context%20like%20the%20current%20conversation" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. Past messages from both the user and the AI assistant are shown in chronological order (often with visual distinctions like labels or colored text to tell user messages from AI responses). This log is read-only; it\u8217\'92s essentially the history view. As the conversation progresses, new messages appear here in a threaded format}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,context%20like%20the%20current%20conversation" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls1 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Message Input & Controls (Right Panel, bottom):}{\loch
 Below the chat log is a text input field where the user can type their message or question to the AI}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,context%20like%20the%20current%20conversation" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. Next to it is a }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Send}{\loch
 button (often depicted with a paper plane icon) that submits the message to the AI when clicked}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,context%20like%20the%20current%20conversation" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. Pressing Enter (if supported) would also send the message. Once sent, the user\u8217\'92s query is added to the chat log above, and shortly afterward the AI\u8217\'92s reply will appear beneath it, much like a typical chat conversation}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,context%20like%20the%20current%20conversation" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls1 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Prompt Template Selector:}{\loch
 At the top of the input area, there is a dropdown menu to choose a }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Workshop Prompt Preset}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,the%20level%20of%20detail%20or" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. These presets are user-customizable prompts that set the behavior or role of the AI during the chat. For example, one preset might be \u8220\'93Brainstorm Ideas\u8221\'94 which primes the AI to generate creative plot ideas, while another might be \u8220\'93In-world Dialogue\u8221\'94 which instructs the AI to role-play as a character. Selecting a different prompt preset changes the initial context or \u8220\'93system\u8221\'94 instruction given to the AI, thus altering its responses}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,the%20level%20of%20detail%20or" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. (Under the hood, these correspond to templates defined in the app\u8217\'92s prompt settings for the Workshop category.)}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls1 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Model/Fidelity Mode Display:}{\loch
 Next to or below the prompt selector, the interface displays the AI model or configuration being used (e.g. \u8220\'93Model: GPT-4\u8221\'94 or a local model\u8217\'92s name) and possibly a }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
mode selector}{\loch
 for response detail level}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=Prompt%20Selector%20dropdown%20containing%20different,use%20shorter%20replies%20to%20save" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. In Writingway, there are }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Chat Fidelity}{\loch
 modes (sometimes labeled as }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Normal}{\loch
, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Economy}{\loch
, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Ultra-Light}{\loch
 or similar) that control how the chat history is managed and how verbose the AI\u8217\'92s replies might be}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=configuration%20,speed%2Fcost%20in%20the%20AI\u8217\'92s%20answers" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. We\u8217\'92ll discuss these modes in detail later. The selected prompt preset may also implicitly choose a model; the UI shows the active model name to remind the user}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=you%20might%20have%20a%20\u8220\'93Brainstorm,use%20shorter%20replies%20to%20save" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls1 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Context Panel Toggle:}{\loch
 There is an option (often a button with a book icon) to open the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Context Panel}{\loch
 within the workshop chat window}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,a%20continuation%20or%20elaborate%20on" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. Toggling this will slide in a panel (usually on the right side of the Workshop window) that displays the project\u8217\'92s scene tree and compendium, allowing the user to select what context to include in the conversation. (Details on this in the next section.)}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
Overall, the Workshop chat UI is designed to be familiar to anyone who has used chat apps or ChatGPT, while integrating additional controls for writing-specific context. It\u8217\'92s been described as \u8220\'93very similar to ChatGPT\u8221\'94 in appearance, with numbered UI elements: }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
1)}{\loch
 conversation threads list, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
2)}{\loch
 new chat button, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
3)}{\loch
 fidelity mode selector, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
4)}{\loch
 prompt preset dropdown, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
5)}{\loch
 send button and context toggle, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
6)}{\loch
 context selection panel, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
7)}{\loch
 message input field, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
8)}{\loch
 chat history area}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=ImageThe%20chat%20interface%2C%20very%20similar,type%20here%2C%208%3A%20chat%20history" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s2\rtlch\af10\afs36\ab \ltrch\hich\af3\loch\ilvl1\outlinelevel1\sb200\sa120\keepn\f3\fs36\b\dbch\af8\ql\ltrpar{\loch
Managing Multiple Chat Sessions}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
One key feature of the Workshop is the ability to handle }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
multiple chat sessions}{\loch
 in parallel. Each item in the left conversation list is essentially a separate session with its own history}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,without%20context%20from%20previous%20chats" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. When you start a new chat, the previous chat\u8217\'92s content isn\u8217\'92t lost \u8211\'96 it\u8217\'92s just stored under its session. You can click on \u8220\'93Chat 1\u8221\'94, \u8220\'93Chat 2\u8221\'94, etc., to revisit those transcripts at any time during the session. This is useful, for example, if you want to brainstorm different ideas in isolation: you might have one chat where the AI helps outline Chapter 1, and another chat where it helps develop a side character\u8217\'92s backstory. Each chat thread remembers only its own dialogue, preventing contexts from bleeding into each other.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
When the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
\u8220\'93New Chat\u8221\'94}{\loch
 button is pressed, the application likely saves the current conversation (in memory) under the current thread name and opens a fresh empty log as a new thread. The new chat gets a default name (like an incremented \u8220\'93Chat 2\u8221\'94, \u8220\'93Chat 3\u8221\'94, etc.)}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=chat%20session%2C%20so%20you%20can,without%20context%20from%20previous%20chats" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. In the current Python implementation, these chats persist at least for the duration of the program runtime. (It\u8217\'92s not explicitly stated if they are saved to disk, but the user can manually copy content out if needed.) The interface does not currently show custom names or allow renaming of chat threads, so they remain numbered. In rewriting this feature, one might consider saving these conversations (e.g., in a JSON file per project) so that chats could be resumed across application restarts, but that depends on design choices. For now, think of the chat threads as multiple tabs of a chat \u8212\'97 you can switch between them freely, and the context for each is kept separate.}
\par \pard\plain \s2\rtlch\af10\afs36\ab \ltrch\hich\af3\loch\ilvl1\outlinelevel1\sb200\sa120\keepn\f3\fs36\b\dbch\af8\ql\ltrpar{\loch
Sending Messages and Receiving AI Responses}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
Using the Workshop chat is straightforward: you type a message and send it, and an AI reply comes back. Under the hood, however, there\u8217\'92s a lot happening to format the prompt and maintain the dialogue state:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls2 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
User Message Submission:}{\loch
 When the user enters text in the input box and clicks }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Send}{\loch
, that text is captured as the next user message in the conversation}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,context%20like%20the%20current%20conversation" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. The UI immediately appends the user\u8217\'92s message to the chat log (often with a label like \u8220\'93You:\u8221\'94 or some styling to indicate it\u8217\'92s the user speaking).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls2 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Prompt Assembly:}{\loch
 Before contacting the AI, Writingway builds the prompt. It takes into account:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls2 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
The selected }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Workshop prompt preset}{\loch
 (which may provide a system-level instruction or opening for the AI).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls2 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
The ongoing }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
conversation history}{\loch
 (previous messages in that chat thread).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls2 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
Any selected }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
context}{\loch
 (scenes/notes from the project, or compendium entries).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\fi0\li709\lin709\ltrpar{\loch
The program }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
\u8220\'93handles formatting the prompt behind the scenes\u8221\'94}{\loch
, meaning it automatically assembles all these pieces into the query sent to the model}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=chat%20log%20is%20read,if%20context%20mode%20is%20on" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. For example, if the preset is \u8220\'93Brainstorm Ideas\u8221\'94, the system might prepend a directive like \u8220\'93You are a creative writing assistant helping brainstorm ideas for a story. Be imaginative and detailed.\u8221\'94 Then it may include a summary of relevant context (like \u8220\'93The story so far: [brief summary or selected context]\u8221\'94) and then the recent chat messages. Finally, it appends the latest user question. This construction is done in code each time a message is sent, so that the AI always receives the full necessary context and instructions.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls2 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
LLM Integration Call:}{\loch
 Once the prompt is prepared, the application sends it to the configured AI model. Writingway supports multiple backends \u8211\'96 it can call OpenAI/Anthropic APIs or use local models (via OpenRouter, Ollama, etc.), depending on user settings}{{\field{\*\fldinst HYPERLINK "https://www.reddit.com/r/WritingWithAI/comments/1iqqi86/writingway_a_free_open_source_software_that/#:~:text=But%20in%20the%20end%2C%20nothing,It%27s%20FREE" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
reddit.com}{}}}\loch
. The }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
llm_integration.py}{\loch
 module abstracts these details. For an online API like OpenAI\u8217\'92s, it likely uses a chat completion endpoint with the messages array (roles: system, user, assistant, etc.). For local models, it might use an HTTP endpoint or LangChain integration. In all cases, the call is asynchronous from the UI perspective \u8211\'96 meaning the UI might show a spinner or just remain responsive while waiting for the reply.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls2 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
AI Response Handling:}{\loch
 When the AI generates a response, the program receives that text and then appends it to the chat history as a new message (often labeled or styled as from the AI, e.g., \u8220\'93Assistant: \u8230\'85\u8221\'94). The chat log in the UI updates to display the AI\u8217\'92s answer directly under the user\u8217\'92s question, creating the conversational flow}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,context%20like%20the%20current%20conversation" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. The user can then continue the conversation by typing another message, and the cycle repeats. The back-and-forth continues for as long as needed, with the history growing and being managed according to the fidelity settings (discussed below).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls2 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Maintaining Chat State:}{\loch
 Internally, each message (user or assistant) is stored as part of the current chat session\u8217\'92s data structure \u8211\'96 typically as a list of messages. This could be as simple as a list of dicts like }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
\{"role": "user", "content": "..."\}}{\loch
 and }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
\{"role": "assistant", "content": "..."\}}{\loch
, or possibly a LangChain memory object. This in-memory history is what\u8217\'92s used to construct new prompts on each turn, ensuring the model has context of previous exchanges. The UI\u8217\'92s chat log is basically a reflection of this data structure.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls2 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Formatting and Limitations:}{\loch
 The chat log is read-only for past messages; you cannot edit earlier messages, only scroll through them. If the conversation gets very long, at some point the program will start to trim or summarize it (see }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Conversation Memory}{\loch
 section) to avoid exceeding token limits. In terms of formatting, the Workshop chat doesn\u8217\'92t do anything too fancy like chat bubbles with avatars; it\u8217\'92s a text-based log. However, it does ensure a clear separation of turns and might support basic text formatting in messages (for instance, the AI\u8217\'92s messages might include markdown or the user could use simple markup).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
In summary, sending a message triggers a sequence where the app builds a combined prompt including any necessary context, sends it to the chosen LLM, and then displays the result. This is all initiated by the simple action of clicking Send, making the experience seamless for the user}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,context%20like%20the%20current%20conversation" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s2\rtlch\af10\afs36\ab \ltrch\hich\af3\loch\ilvl1\outlinelevel1\sb200\sa120\keepn\f3\fs36\b\dbch\af8\ql\ltrpar{\loch
Prompt Presets and AI Configuration}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
A powerful aspect of Writingway\u8217\'92s workshop chat is the ability to customize }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
how the AI behaves}{\loch
 by using different prompt presets and model settings:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls3 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Workshop Prompt Presets:}{\loch
 At the top of the chat interface, the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Prompt}{\loch
 dropdown lets the user select from pre-defined scenarios or styles for the chat}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,the%20level%20of%20detail%20or" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. These presets are defined in the application\u8217\'92s prompt configuration (often via a JSON in the project or a settings panel) and belong to the }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Workshop}{\loch
 category of prompts. For example, you might have:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls3 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs18\rtlch\ai \ltrch\loch\i
\u8220\'93}{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Brainstorm Ideas\u8221\'94}{\loch
: The AI is prompted to freely come up with plot ideas or twists.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls3 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs18\rtlch\ai \ltrch\loch\i
\u8220\'93}{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Character Roleplay\u8221\'94}{\loch
: The AI is instructed to assume the role of a specific character and answer as them.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls3 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs18\rtlch\ai \ltrch\loch\i
\u8220\'93}{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Critique and Suggest\u8221\'94}{\loch
: The AI is directed to act as an editor giving feedback on whatever the user says.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\fi0\li709\lin709\ltrpar{\loch
When a preset is chosen, Writingway uses the corresponding template text for the AI\u8217\'92s system instruction or the way it structures the conversation. This template might also include guidelines (like expected tone or format of AI responses). }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
In practice, selecting a preset immediately affects the chat \u8211\'96 the next AI response will follow that prompt\u8217\'92s style.}{\loch
 The UI might reset the conversation or it might allow changing presets mid-chat (the implementation suggests the preset can be changed on the fly, though doing so in the middle of a conversation might produce unpredictable results unless the system prompt is resent). Each preset is fully editable by the user in the }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Prompt Options}{\loch
 menu of Writingway (outside the chat), meaning you can craft exactly what the AI\u8217\'92s \u8220\'93persona\u8221\'94 or task is for the workshop}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,the%20level%20of%20detail%20or" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls3 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Model and Configuration per Prompt:}{\loch
 Writingway allows different presets to use different models or API endpoints. In the UI, next to the prompt selector, it shows }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
\u8220\'93Model: [Name]\u8221\'94}{\loch
 indicating which LLM is currently assigned to the chosen preset}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=you%20might%20have%20a%20\u8220\'93Brainstorm,the%20level%20of%20detail%20or" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. For instance, you could have the \u8220\'93Brainstorm\u8221\'94 preset configured to use a powerful model like GPT-4 for more creative output, and a \u8220\'93Quick Chat\u8221\'94 preset using a faster, cheaper model. When the user switches the preset, the model label updates accordingly}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=you%20might%20have%20a%20\u8220\'93Brainstorm,use%20shorter%20replies%20to%20save" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. This is because in the prompt settings, each entry stores not just the prompt text but also the model/provider to use (and possibly parameters like temperature). The benefit is flexibility \u8211\'96 you can tailor the AI\u8217\'92s capabilities and cost to the task at hand. In rewriting this feature, one would mirror this by allowing each chat mode to point to a different backend or model instance as needed.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls3 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Fidelity (Detail Level) Modes:}{\loch
 Another control visible in the chat interface is the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
\u8220\'93Fidelity\u8221\'94 mode selector (chat detail mode)}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=configuration%20,speed%2Fcost%20in%20the%20AI\u8217\'92s%20answers" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. This is usually a dropdown or toggle with options that might be labeled something like }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
High}{\loch
, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Balanced}{\loch
, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Compressed}{\loch
 (or previously referred to as Normal/Economy/Ultra-light). These modes govern how the chat history is handled and how verbose the AI\u8217\'92s answers should be. In effect, they manage the balance between giving the AI a lot of detail (which uses more tokens and could be slower) and brevity (which saves tokens but might lose nuance). According to the documentation:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls3 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
High Fidelity:}{\loch
 preserves almost the entire chat history with full detail. The AI sees everything that\u8217\'92s been said in detail, which is ideal when context is crucial}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,brevity%20are%20prioritized%20over%20detail" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls3 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Balanced Fidelity:}{\loch
 keeps a medium amount of detail \u8211\'96 it might summarize or omit minor parts of the history while keeping important context intact}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,brevity%20are%20prioritized%20over%20detail" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls3 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Compressed Fidelity:}{\loch
 aggressively compresses the conversation, keeping only the key points from earlier messages and possibly giving the AI shorter prompts/replies}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,brevity%20are%20prioritized%20over%20detail" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\fi0\li709\lin709\ltrpar{\loch
The user can switch these modes depending on their needs. For instance, if they notice the AI starting to forget earlier context or contradict itself, they might choose High Fidelity so more history is preserved. Conversely, if they are just doing a quick brainstorming and want to minimize token usage (or if the conversation got too long), Compressed mode will summarize older content. We will discuss }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
how}{\loch
 the app implements these modes in the next section, but from a user perspective this is a simple way to tune the AI\u8217\'92s behavior: higher fidelity = more detailed, longer responses and context; lower fidelity = more concise and focused responses}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=Why%20does%20Chat%20Fidelity%20matter,avoid%20confusion%20or%20token%20overflow" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=When%20is%20Balanced%20Fidelity%20the,that%20benefit%20from%20moderate%20context" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
In summary, the Workshop chat\u8217\'92s top controls let the user }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
steer the AI\u8217\'92s behavior}{\loch
: the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Prompt Preset}{\loch
 defines }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
what role or style}{\loch
 the AI should adopt, the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Model}{\loch
 selection defines }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
which AI}{\loch
 is answering (and how powerful/costly it is), and the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Fidelity Mode}{\loch
 defines }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
how much context}{\loch
 to maintain and the verbosity of the exchange}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,the%20level%20of%20detail%20or" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=configuration%20,speed%2Fcost%20in%20the%20AI\u8217\'92s%20answers" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. These all work together to customize the chat experience for different creative needs.}
\par \pard\plain \s2\rtlch\af10\afs36\ab \ltrch\hich\af3\loch\ilvl1\outlinelevel1\sb200\sa120\keepn\f3\fs36\b\dbch\af8\ql\ltrpar{\loch
Context Integration via the Workshop\u8217\'92s Context Panel}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
A standout feature of Writingway\u8217\'92s Workshop Chat is its deep integration with the user\u8217\'92s writing }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
context}{\loch
 \u8211\'96 the content of the manuscript and world-building notes. This is achieved through the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Context Panel}{\loch
, which can be shown alongside the chat:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls4 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Project Tree and Compendium View:}{\loch
 When the context panel is opened, it presents a combined view of the project\u8217\'92s structure (scenes/chapters/acts) and the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Compendium}{\loch
 (the world-building encyclopedia)}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,The" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. Essentially, you might see a tree on one side with all acts -> chapters -> scenes, and possibly another tree or list of compendium categories -> entries. This panel is interactive; it allows the user to pick which pieces of text should be fed into the AI as context.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls4 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Selecting Context Items:}{\loch
 The user can check or highlight specific scenes or compendium entries in the context panel that are relevant to the current discussion}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,The" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. For example, if the user is brainstorming a scene that involves }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Alice}{\loch
 and }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Bob}{\loch
 at the }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Enchanted Forest}{\loch
, the user might select Alice\u8217\'92s character entry (from Compendium > Characters > Alice) and the Enchanted Forest entry (from Compendium > Locations) along with perhaps the previous scene\u8217\'92s text. By selecting these, the user is signaling: \u8220\'93include these details in the prompt so the AI knows about them.\u8221\'94 The interface likely uses checkboxes or multi-select for this purpose.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls4 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Including Context in Prompts:}{\loch
 Once context items are selected, when the user sends a message, the program will automatically pull the text of those selected items and incorporate them into the prompt sent to the AI}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,The" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. This might be done by concatenating the text or by constructing a special part of the prompt, e.g., \u8220\'93}{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Context:}{\loch
 [content of scene/entry]\u8221\'94. The idea is to give the AI additional knowledge: it could be the backstory of a character, a summary of what happened earlier in the plot, or specific details like magic system rules \u8211\'96 whatever the user deems relevant. This significantly grounds the AI\u8217\'92s responses in the actual story, preventing it from going off-track or contradicting established facts}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,The%20system%20can%20parse" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls4 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Dynamic Compendium References:}{\loch
 Besides manual selection, Writingway can }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
automatically leverage compendium references}{\loch
 that appear in the conversation. According to the documentation, the system can }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
\u8220\'93parse references to compendium entries in your messages and replace them with the actual content\u8221\'94}{\loch
 of those entries}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=the%20compendium%20to%20avoid%20contradictions,richness%20in%20the%20AI\u8217\'92s%20output" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. For instance, if the user types: }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
\u8220\'93What would }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Alice}{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
 do in this situation?\u8221\'94}{\loch
 \u8211\'96 and \u8220\'93Alice\u8221\'94 is a compendium entry (say a character profile) \u8211\'96 the program can detect that \u8220\'93Alice\u8221\'94 is a known entity and inject Alice\u8217\'92s background info into the prompt for the AI. This might happen behind the scenes: the user\u8217\'92s message remains \u8220\'93What would Alice do...\u8221\'94, but the actual prompt to AI might have an extra section appended like \u8220\'93Alice\u8217\'92s profile: [Alice\u8217\'92s compendium text]\u8221\'94. This ensures the AI is aware of Alice\u8217\'92s character traits when formulating an answer. The user doesn\u8217\'92t necessarily see this injection; it\u8217\'92s done transparently to enrich context}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=the%20compendium%20to%20avoid%20contradictions,richness%20in%20the%20AI\u8217\'92s%20output" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. (In implementing this in a new version, one would likely have to parse the user\u8217\'92s input for keywords matching compendium entries or require a special syntax to denote such references.)}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls4 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Avoiding Token Overload:}{\loch
 The context panel gives fine-grained control so the user can include only what\u8217\'92s needed. In practice, you wouldn\u8217\'92t dump }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
all}{\loch
 of your world info into each prompt \u8211\'96 you\u8217\'92d pick the pertinent pieces. Writingway likely also imposes some limits (it might warn or prevent selecting too many large texts that would exceed token limits). The }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
context selection panel}{\loch
 is essentially a prompt builder helper, letting you cherry-pick story elements for the AI. This is much more efficient than always sending the entire novel or compendium.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls4 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Use Case Example:}{\loch
 Suppose you\u8217\'92re at Chapter 5 and using the workshop chat to brainstorm the next scene. You might select the summary of Chapter 4 and the profiles of two characters who will be in the scene. When you ask the AI \u8220\'93How could this confrontation play out?\u8221\'94, it will see those selected contexts and might answer with knowledge of what happened in Chapter 4 and the characters\u8217\'92 personalities, leading to a consistent and informed suggestion.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
In summary, the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Context Panel}{\loch
 feature tightly integrates the chat with the rest of Writingway. It }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
\u8220\'93shows your project\u8217\'92s tree and compendium side by side\u8221\'94}{\loch
 and lets you pick which pieces of lore or previous text to include}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,The" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. By using it, }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
\u8220\'93you can ensure the AI has the right context when generating text\u8221\'94}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=side%20within%20the%20Workshop%20window,The" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
 \u8211\'96 effectively the AI can be made as knowledgeable about your story as you need it to be. This is crucial for maintaining continuity and depth in AI-generated ideas. When rebuilding this in Java/HTML, one would implement a similar sidebar with project structure and notes, allow multi-selection, and then programmatically concatenate those selections into the prompt for the AI.}
\par \pard\plain \s2\rtlch\af10\afs36\ab \ltrch\hich\af3\loch\ilvl1\outlinelevel1\sb200\sa120\keepn\f3\fs36\b\dbch\af8\ql\ltrpar{\loch
Conversation Memory Management and Summarization (Chat Fidelity)}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
Because the Workshop Chat can be an ongoing conversation, there\u8217\'92s a potential issue: }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
long chats can exceed the token limit of the model}{\loch
 or become unwieldy. Writingway addresses this with its }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Chat Fidelity modes}{\loch
 and conversation summarization.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls5 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Need for Summarization:}{\loch
 As you continue chatting, earlier parts of the conversation become context for later messages. However, models have finite context windows. To manage this, Writingway will }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
summarize or compress older messages}{\loch
 once the history grows too large}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=\u8220\'93remember\u8221\'94%20specific%20details%20from%20your,when%20it%20gets%20too%20long" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. This is done intelligently to retain important info while freeing up space. The application\u8217\'92s changelog specifically notes }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
\u8220\'93Implemented chat summarization for longer workshop chats.\u8221\'94}{{\field{\*\fldinst HYPERLINK "https://www.reddit.com/r/WritingWithAI/comments/1iqqi86/writingway_a_free_open_source_software_that/#:~:text=,It%20skips%20it%20now" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
reddit.com}{}}}\loch
, meaning this is a built-in feature to prevent the chat from hitting length limits.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls5 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Chat Fidelity Modes (Revisited):}{\loch
 The fidelity setting essentially controls the aggressiveness of this summarization:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls5 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
High Fidelity:}{\loch
 The program will preserve almost all detail. It will only summarize if absolutely necessary (when hitting hard limits), and even then it will aim to keep the summary very detailed}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,brevity%20are%20prioritized%20over%20detail" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. This mode favors keeping context, at the cost of possibly larger prompts.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls5 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Balanced Fidelity:}{\loch
 The program will summarize earlier parts of the chat moderately. Less important details or repetitive bits will be condensed, but key points and critical context are kept verbose}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,brevity%20are%20prioritized%20over%20detail" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. This balances context completeness with token economy.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls5 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Compressed Fidelity:}{\loch
 The program will aggressively condense the chat history whenever it grows, keeping only the most essential information from earlier messages}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,brevity%20are%20prioritized%20over%20detail" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. This might involve replacing several turns of dialogue with a short summary paragraph. It\u8217\'92s useful if you want to minimize cost or if the details aren\u8217\'92t crucial beyond the big picture (e.g., during quick brainstorming)}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=When%20is%20Balanced%20Fidelity%20the,that%20benefit%20from%20moderate%20context" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls5 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
How Summarization Works:}{\loch
 Under the hood, when summarization is triggered, Writingway likely uses the AI itself or a utility to compress the conversation:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls5 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
It may take the oldest part of the conversation (e.g., the first N messages) and feed them to a summarizing function (possibly using an LLM prompt like \u8220\'93Summarize this conversation so far in 100 words\u8221\'94). The result would be a short synopsis of that portion.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls5 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
The program then }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
replaces}{\loch
 those original messages in the history with a single summary entry. For example, 10 messages could be replaced by one summary message (maybe marked as such, like an assistant message saying \u8220\'93(Summary of earlier discussion: ...)\u8221\'94). This way, the effective history is shorter, but still contains the important points for the AI to remember going forward}{{\field{\*\fldinst HYPERLINK "https://www.reddit.com/r/WritingWithAI/comments/1iqqi86/writingway_a_free_open_source_software_that/#:~:text=,It%20skips%20it%20now" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
reddit.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls5 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
The summarization respects any protected information. If the user marked something as important (see next point), or if something looks crucial (names, plot twists), the summarizer should include those or leave them untouched.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls5 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
This process might repeat if the conversation continues to grow. Essentially, the chat history becomes a mix of actual recent messages and summarized blocks of older messages, according to the fidelity mode\u8217\'92s rules.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls5 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Protecting Important Details:}{\loch
 Writers may not want certain details to get lost in summarization. The Workshop has a convention: if you }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
wrap text in asterisks}{\loch
 (e.g. }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
*the killer\u8217\'92s identity is John*}{\loch
), the system will treat that as important and try to }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
preserve it verbatim}{\loch
 even in summaries}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=How%20does%20the%20application%20decide,on%20the%20fidelity%20mode%20selected" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. The FAQ explicitly says you can mark details to prevent compression by wrapping them in asterisks}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=Can%20I%20mark%20important%20details,of%20the%20chosen%20fidelity%20mode" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. So during summarization, the algorithm likely scans for }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
*...*}{\loch
 and ensures that content either stays in the summary or is not removed. This is a user-friendly way to highlight what must not be forgotten.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls5 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Example of Fidelity in Action:}{\loch
 Suppose you have a very long brainstorming chat (dozens of exchanges). In High fidelity mode, the AI is always given the full (or nearly full) conversation each time, which maximizes continuity (the AI remembers everything) but might be slow or eventually impossible if too long. In Balanced mode, maybe after 20 exchanges, the first 10 get summarized into a shorter form \u8211\'96 the AI from then on sees the summary + the last 10 detailed exchanges. In Compressed mode, maybe after every 10 exchanges the earlier 5 are collapsed into a one-paragraph summary, etc. The user might notice that older parts of the chat log get collapsed or annotated as \u8220\'93[Summary of earlier conversation]\u8221\'94, indicating summarization happened. The }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
goal}{\loch
 is to avoid hitting a point where the AI response is cut off or fails due to context length.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls5 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Optimizing Context:}{\loch
 The developers noted they "}{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
optimized the handling of context in the workshop chat}{\loch
"}{{\field{\*\fldinst HYPERLINK "https://www.reddit.com/r/WritingWithAI/comments/1iqqi86/writingway_a_free_open_source_software_that/#:~:text=" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
reddit.com}{}}}\loch
, which suggests ongoing improvements to how the program selects which parts of history to summarize or drop. Likely it tries to remove redundant information and keep the conversation relevant. For instance, if the user asked the same question twice, maybe the first instance can be dropped. Or if a certain side topic ended, those turns can be summarized more heavily.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
In implementing this in a new version, one needs to consider how to count tokens (to decide when to summarize) and possibly use a summarization function. If using OpenAI API, one could use a smaller model to summarize earlier messages, or implement a custom algorithm that identifies and retains important sentences (perhaps via simple NLP). The fidelity modes essentially correspond to thresholds: e.g. High = summarize only when nearing 90% of max context; Balanced = summarize when past 50% of max; Compressed = always summarize beyond the last few messages. The exact numbers are tunable.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Summary of Summarization:}{\loch
 The Workshop chat maintains conversation memory automatically, compressing it as needed. }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
\u8220\'93High Fidelity preserves almost the entire chat history,\u8221\'94 \u8220\'93Balanced Fidelity strikes a compromise,\u8221\'94 and \u8220\'93Compressed Fidelity retains only the most essential points.\u8221\'94}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=What%20are%20the%20available%20Chat,Fidelity%20modes" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. The application }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
\u8220\'93analyzes your chat history, preserving messages marked as important... and summarizes or removes less critical content based on the fidelity mode\u8221\'94}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=How%20does%20the%20application%20decide,on%20the%20fidelity%20mode%20selected" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. This ensures the AI has enough context to be useful, without exceeding limits or getting confused by too much irrelevant detail.}
\par \pard\plain \s2\rtlch\af10\afs36\ab \ltrch\hich\af3\loch\ilvl1\outlinelevel1\sb200\sa120\keepn\f3\fs36\b\dbch\af8\ql\ltrpar{\loch
Internal Implementation Details}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
To replicate the Workshop Chat in another tech stack, it\u8217\'92s important to understand how it\u8217\'92s built in the original Python/PyQt5 version:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls6 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Technology Stack:}{\loch
 Writingway is written in Python (about 99% Python code) and uses }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
PyQt5}{\loch
 for its GUI}{{\field{\*\fldinst HYPERLINK "https://github.com/aomukai/Writingway#:~:text=" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
github.com}{}}}{\field{\*\fldinst HYPERLINK "https://github.com/aomukai/Writingway#:~:text=This%20project%20utilizes%20the%20following,libraries" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
github.com}{}}}\loch
. That means the Workshop chat is a Qt window (possibly a }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
QDialog}{\loch
 or a }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
QMainWindow}{\loch
 subclass) that contains Qt widgets like QListWidget/QTreeWidget (for chat sessions and context trees) and QTextEdit/QPlainTextEdit (for chat log and input). The design is event-driven: clicking buttons and selecting items trigger Python methods.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls6 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Module Organization:}{\loch
 The code for the Workshop likely resides in a module named }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
workshop.py}{\loch
 (and possibly additional files under a }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
workshop}{\loch
 package). Other related modules:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
workbench.py}{\loch
 and }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
project_window_core.py}{\loch
 handle the main UI and project editor.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Context Panel}{\loch
 logic is in }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
context_panel.py}{\loch
, which is used both for the Action Beats (main writing context selection) and the Workshop chat context selection}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=the%20compendium%20to%20avoid%20contradictions,richness%20in%20the%20AI\u8217\'92s%20output" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Prompt handling}{\loch
 is in }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
prompts.py}{\loch
 / }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
prompt_handler.py}{\loch
. These load the prompt presets from JSON (like }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
prompts_MyFirstProject.json}{\loch
) and provide them to the UI dropdowns}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,the%20level%20of%20detail%20or" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
LLM calls}{\loch
 are abstracted in }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
llm_integration.py}{\loch
 and related LangChain usage. Writingway actually leverages }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
LangChain}{\loch
 internally (as indicated by dependencies on }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
langchain-openai}{\loch
, }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
langchain-ollama}{\loch
, etc.)}{{\field{\*\fldinst HYPERLINK "https://github.com/aomukai/Writingway#:~:text=%2A%20faiss" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
github.com}{}}}\loch
. This suggests it uses LangChain classes to interface with different providers (OpenAI, Anthropic, local models) and possibly to assist with tasks like summarization. Essentially, LangChain might manage the creation of a chat model instance or a conversation memory buffer.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls6 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Chat Session Data:}{\loch
 Each chat session (thread) is represented in memory. The simplest approach (likely used) is a list of messages per session. For example, }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
self.chats}{\loch
 could be a list of chat objects, where each chat object has an array }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
messages}{\loch
. Each message could be a tuple or object with }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
role}{\loch
 and }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
content}{\loch
. When you switch chat sessions via the UI list, the program loads the selected chat\u8217\'92s messages into the chat log display. The UI element for the chat log might be a read-only QTextEdit where the text is appended sequentially. (They might also use a Qt ListView with a custom delegate for messages, but given simplicity, appending to a text widget is probable.)}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls6 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Sending Workflow (in code):}{\loch
 When the user hits Send, the event handler will:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
Grab the text from the input widget.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
Determine which prompt preset is active and retrieve its template text and target model.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
Build the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
full prompt}{\loch
. This might involve:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl2\ls6 \fi-283\li0\lin0\ql\tx2127\fi-283\li2127\lin2127\ltrpar{\loch
Starting a LangChain chat chain or creating a messages list. Possibly they create a system message with the prompt template.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl2\ls6 \fi-283\li0\lin0\ql\tx2127\fi-283\li2127\lin2127\ltrpar{\loch
Attaching selected context: they likely have a method like }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
context_text = context_panel.get_selected_text()}{\loch
, which returns a concatenated string of all selected scene/compendium texts. If non-empty, that could be added as another system message or appended to the system prompt.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl2\ls6 \fi-283\li0\lin0\ql\tx2127\fi-283\li2127\lin2127\ltrpar{\loch
Adding the conversation history. If using OpenAI Chat API format, they would iterate through the messages list (except perhaps very old ones if summarized) and add them as }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
\{role: "user"/"assistant", content: ...\}}{\loch
 in order. If using a completion model, they might just concatenate them into a single text block (but given they use LangChain, the chat memory approach is likely).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl2\ls6 \fi-283\li0\lin0\ql\tx2127\fi-283\li2127\lin2127\ltrpar{\loch
Adding the new user message at the end (as the final user role message).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
Call the LLM. With LangChain, this could be something like invoking a }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
ChatModel.predict(messages=conversation)}{\loch
. If not using LangChain for a particular provider, they might call an API endpoint directly (e.g. OpenAI\u8217\'92s }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
openai.ChatCompletion.create}{\loch
). The call is made with the model specified by the preset (they likely have a mapping of provider endpoints configured in settings; e.g., user might have entered their OpenAI API key or a local server URL).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
Await response. This might be done in a separate thread to keep the UI responsive (PyQt requires non-blocking UI). They could use Python\u8217\'92s }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
QThread}{\loch
 or Qt\u8217\'92s signals to handle the asynchronous response arrival. Once the AI returns a message, the handler adds it to the messages list and updates the UI.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
Display the AI\u8217\'92s message in the chat log. This might involve formatting (e.g., prefix "AI:" or just showing it differently). Often, AI messages might be shown in italic or another color to distinguish from user text, but the specifics aren\u8217\'92t given \u8211\'96 likely just labeling by position is enough since user and AI alternate.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls6 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Summarization Implementation:}{\loch
 The code likely monitors the length of }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
messages}{\loch
. Possibly after each new assistant message, it checks the total token count of all messages using a library like }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
tiktoken}{\loch
 (notably, }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
tiktoken}{\loch
 is in the dependencies}{{\field{\*\fldinst HYPERLINK "https://github.com/aomukai/Writingway#:~:text=" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
github.com}{}}}\loch
, which is OpenAI\u8217\'92s tokenization library). If above a threshold (depending on fidelity mode), it triggers a summarize function:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
They might use a smaller prompt or model to summarize. Because LangChain is present, they might be using LangChain\u8217\'92s }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
ConversationSummaryMemory}{\loch
 or similar. This automatically summarizes old conversation and appends a summary to memory.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
Alternatively, they implement their own: e.g., for Balanced mode, if > X tokens, call the same LLM (or a smaller one) with a prompt like \u8220\'93Summarize the following conversation between user and assistant: [full text here]\u8221\'94. Then replace the first N messages with a single summary message.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
The fidelity mode could correspond to different summary lengths. High fidelity might only summarize when near max tokens and produce a long summary; compressed might summarize early and with a very short summary.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
The mention of }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
\u8220\'93preserving messages marked as important\u8221\'94}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=How%20does%20the%20application%20decide,on%20the%20fidelity%20mode%20selected" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
 suggests the summarization function looks for }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
* *}{\loch
 patterns and ensures those segments are copied into the summary unaltered. Implementation-wise, they could strip asterisks and just force-include that text.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
Summaries themselves might be marked in the chat log UI, or hidden from the user. Possibly the user just sees the chat as normal, but internally some earlier entries have been collapsed. (They didn\u8217\'92t specify if the UI indicates summarization, but it might not, to keep things simple.)}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls6 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Context Reference Implementation:}{\loch
 Detecting references (like a character\u8217\'92s name) to inject compendium info likely involves searching the compendium data for a matching entry name. Writingway could use a simple approach: whenever a user message is sent, scan it for any proper-noun or special syntax that matches an entry title. The compendium is stored in JSON (and likely loaded into memory as dictionaries). For each match, append that entry\u8217\'92s content to the context for the prompt. This could also be done via a special notation: maybe the user can type }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
@Alice}{\loch
 or something to explicitly pull Alice\u8217\'92s notes. The blog, however, implies it may be automatic on known names}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=the%20compendium%20to%20avoid%20contradictions,richness%20in%20the%20AI\u8217\'92s%20output" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. This feature means a Java rewrite should include hooking into the world-building DB and being able to fetch text by key.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls6 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Integration with Other Features:}{\loch
 Note that the Workshop chat is part of a larger application. For instance, the }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Prompt Options}{\loch
 window where presets are defined is likely shared with other features (like Prose or Rewrite prompts). The }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Settings}{\loch
 window stores API keys and model endpoints which the Workshop uses when calling the AI}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/02/16/writingway-if-scrivener-had-ai-implementation/#:~:text=,get%20an%20API%20key%20etc" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. Also, the compendium and project structures are managed elsewhere (e.g., in }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
compendium.py}{\loch
 and }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
tree_manager.py}{\loch
), but the Workshop accesses those via the context panel. In rewriting, one must ensure those data sources are accessible to the chat component.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls6 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Example Classes/Functions to Mirror:}{\loch
 While we don\u8217\'92t have the exact code here, one could imagine class outlines:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
class WorkshopWindow(QDialog):}{\loch
 with attributes like }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
self.chat_list}{\loch
 (QListWidget), }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
self.chat_display}{\loch
 (QTextEdit), }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
self.input_field}{\loch
 (QLineEdit), }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
self.prompt_combo}{\loch
 (QComboBox), }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
self.mode_combo}{\loch
 (QComboBox), }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
self.context_panel}{\loch
 (maybe a custom widget).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl2\ls6 \fi-283\li0\lin0\ql\tx2127\fi-283\li2127\lin2127\ltrpar{\loch
Methods like }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
new_chat()}{\loch
, }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
switch_chat(index)}{\loch
, }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
send_message()}{\loch
, }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
receive_response(response)}{\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
class ChatSession:}{\loch
 to encapsulate a list of messages and maybe the current prompt template in use.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
class PromptManager:}{\loch
 to load/save prompt presets and provide the text+model for a given preset selection.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl1\ls6 \fi-283\li0\lin0\ql\tx1418\fi-283\li1418\lin1418\ltrpar{\loch
Using Qt\u8217\'92s signal-slot mechanism, e.g., }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
send_button.clicked.connect(self.send_message)}{\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls6 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
LangChain Usage:}{\loch
 The inclusion of LangChain libraries for OpenAI, Anthropic, Google, Ollama indicates that the developer chose to use a unified API (LangChain) to talk to different LLM providers. They probably initialize a LangChain LLM object for each configured model (like an }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
OpenAI}{\loch
 instance for OpenAI API, an }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
Anthropic}{\loch
 instance for Claude, an }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
Ollama}{\loch
 for local models, etc.) depending on user selection. LangChain also offers memory components; it\u8217\'92s possible the Workshop chat leverages a }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
ConversationBufferMemory}{\loch
 or }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
ConversationSummaryMemory}{\loch
 to help automatically manage the context. However, given this is an application, they might not fully rely on LangChain\u8217\'92s memory (which is more for building conversational agents in code) and instead manually manage the chat history as described.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls6 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Voice/TTS (irrelevant here):}{\loch
 The presence of }{\loch\cs19\rtlch\af5 \ltrch\hich\af5\loch\f5\dbch\af9\loch
pyttsx3}{\loch
 (text-to-speech) in dependencies}{{\field{\*\fldinst HYPERLINK "https://github.com/aomukai/Writingway#:~:text=" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
github.com}{}}}\loch
 suggests the app can read out text (there\u8217\'92s a TTS button in the main editor). But that\u8217\'92s separate from the Workshop chat; the chat feature itself is textual (no voice input or output by default). We can ignore TTS for the chat rewrite.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
By understanding these internals, one can recreate the Workshop chat in Java/HTML. In a Java context (perhaps using JavaFX or a web UI), the analogous structure would be: a panel for chat threads, a text area for chat history, a text field for input with send button, combos for preset and mode, and a side panel for context (which might list project files and notes). The logic to handle message sending, context injection, and summarization would be implemented similarly: maintain a list of messages, and use an AI API (maybe via HTTP calls) to get responses. Also, implement summarization when needed (perhaps call the same AI to summarize or use an algorithm). The Java version would need to manage state and asynchronous calls (maybe using threads or async tasks) akin to how the Python version uses threads or Qt\u8217\'92s concurrency.}
\par \pard\plain \s2\rtlch\af10\afs36\ab \ltrch\hich\af3\loch\ilvl1\outlinelevel1\sb200\sa120\keepn\f3\fs36\b\dbch\af8\ql\ltrpar{\loch
Conclusion}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
In summary, the }{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Workshop Chat}{\loch
 in Writingway is essentially an AI chat system tightly integrated with a writing project\u8217\'92s data. It\u8217\'92s built with a GUI that supports multiple chat sessions, rich context injection from the user\u8217\'92s own story, and tools to manage the conversation length. The feature is powered by configurable prompt templates and can interface with various AI models (local or cloud) based on user preference}{{\field{\*\fldinst HYPERLINK "https://www.reddit.com/r/WritingWithAI/comments/1iqqi86/writingway_a_free_open_source_software_that/#:~:text=But%20in%20the%20end%2C%20nothing,It%27s%20FREE" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
reddit.com}{}}}\loch
. As the conversation grows, it employs summarization strategies to retain important context while avoiding overflow}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=How%20does%20the%20application%20decide,on%20the%20fidelity%20mode%20selected" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
. All these components work together to provide a seamless experience where an author can brainstorm with an AI as if it were a co-writer familiar with their story\u8217\'92s details.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
When rewriting this in Java/HTML, one would recreate the UI layout (chats list, messages view, input box, context sidebar, etc.), and implement the logic for:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls7 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch
Managing multiple chat sessions (data structures for conversations).}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls7 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch
Loading and applying prompt presets and associated model configs.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls7 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch
Fetching AI responses via appropriate APIs.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls7 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch
Allowing insertion of custom context (story text/notes) into the AI prompt.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls7 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch
Summarizing or truncating the history according to a user-selected mode.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch
By mirroring the described behavior and architecture, the new implementation can achieve feature parity with the original Python version. This ensures that authors continue to benefit from interactive, context-rich AI assistance in their writing workflow}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,The" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=the%20compendium%20to%20avoid%20contradictions,richness%20in%20the%20AI\u8217\'92s%20output" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140\ql\ltrpar{\loch\cs15\rtlch\ab \ltrch\loch\b\loch
Sources:}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls8 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch
A. Omukai\u8217\'92s }{\loch\cs18\rtlch\ai \ltrch\loch\i\loch
Writingway}{\loch
 introduction and update posts \u8211\'96 describing the Workshop Chat interface and features}{{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,a%20text%20box%20where%20you" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,The" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=,brevity%20are%20prioritized%20over%20detail" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}{\field{\*\fldinst HYPERLINK "https://aomukai.com/2025/03/09/writingway-updated/#:~:text=How%20does%20the%20application%20decide,on%20the%20fidelity%20mode%20selected" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
aomukai.com}{}}}\loch
.}
\par \pard\plain \s21\loch\sl276\slmult1\sb0\sa140{\listtext\pard\plain \rtlch\af6 \ltrch\hich\af6\loch\f6\dbch\af6 \u8226\'95\tab}\ilvl0\ls8 \fi-283\li0\lin0\ql\tx709\fi-283\li709\lin709\ltrpar{\loch
Writingway project documentation and Reddit Q&A \u8211\'96 outlining design goals like chat summarization and multi-provider support}{{\field{\*\fldinst HYPERLINK "https://www.reddit.com/r/WritingWithAI/comments/1iqqi86/writingway_a_free_open_source_software_that/#:~:text=,It%20skips%20it%20now" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
reddit.com}{}}}{\field{\*\fldinst HYPERLINK "https://www.reddit.com/r/WritingWithAI/comments/1iqqi86/writingway_a_free_open_source_software_that/#:~:text=But%20in%20the%20end%2C%20nothing,It%27s%20FREE" \\t "_blank" }{\fldrslt {\loch\loch\cf9\ul\ulc0\loch
reddit.com}{}}}\loch
.}
\par \pard\plain \s0\rtlch\af10\afs24\alang1081 \ltrch\lang1031\langfe2052\hich\af3\loch\widctlpar\hyphpar0\ltrpar\cf0\f3\fs24\lang1031\kerning1\dbch\af8\langfe2052\ql\ltrpar\loch

\par }